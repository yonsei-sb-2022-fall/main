{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅데이터 분석프로그래밍 2 - Week 06\n",
    "카메라 기능과 cv2를 활용하여 얼굴 인식 프로그램을 만들어 보도록 하겠습니다.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 얼굴인식 알고리즘 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 캐스케이드 파일 지정해서 검출기 생성하기 --- (*1)\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# 이미지를 읽어 들이고 그레이스케일로 변환하기 --- (*2)\n",
    "img = cv2.imread(\"face.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 얼굴 인식하기 --- (*3)\n",
    "face_list = cascade.detectMultiScale(img_gray)\n",
    "\n",
    "\n",
    "# 인식한 부분 표시하기 --- (*4)\n",
    "x,y,w,h = face_list[0]\n",
    "print(\"얼굴의 좌표 =\", x, y, w, h)\n",
    "red = (0, 0, 255)\n",
    "cv2.rectangle(img, (x, y), (x+w, y+h), red, thickness=20)\n",
    "\n",
    "# 이미지 출력하기\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. 여러명의 얼굴을 인식 할 수 있게 위의 코드를 수정한다면?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 캐스케이드 파일 지정해서 검출기 생성하기 --- (*1)\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# 이미지를 읽어 들이고 그레이스케일로 변환하기 --- (*2)\n",
    "img = cv2.imread(\"faces.jpeg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 얼굴 인식하기 --- (*3)\n",
    "face_list = cascade.detectMultiScale(img_gray)\n",
    "\n",
    "##이부분을 수정해주세요!\n",
    "##hint: 반복문\n",
    "\n",
    "\n",
    "face = face_list[0]\n",
    "# 인식한 부분 표시하기 --- (*4)\n",
    "x,y,w,h = face\n",
    "print(\"얼굴의 좌표 =\", x, y, w, h)\n",
    "red = (0, 0, 255)\n",
    "cv2.rectangle(img, (x, y), (x+w, y+h), red, thickness=2)\n",
    "\n",
    "# 이미지 출력하기\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 얼굴에 모자이크 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(img, rect, size):\n",
    "    # 모자이크 적용할 부분 추출하기\n",
    "    (x1, y1, x2, y2) = rect\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    i_rect = img[y1:y2, x1:x2]\n",
    "    # 축소하고 확대하기\n",
    "#     print(img.shape)\n",
    "#     print(i_rect.shape)\n",
    "#     plt.imshow(i_rect)\n",
    "#     plt.show()\n",
    "    i_small = cv2.resize(i_rect, ( size, size))\n",
    "#     print(i_small.shape)\n",
    "#     plt.imshow(i_small)\n",
    "#     plt.show()\n",
    "    i_mos = cv2.resize(i_small, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     print(i_mos.shape)\n",
    "#     plt.imshow(i_mos)\n",
    "#     plt.show()\n",
    "    # 모자이크 적용하기\n",
    "    img2 = img.copy()\n",
    "    img2[y1:y2, x1:x2] = i_mos\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 캐스케이드 파일 지정해서 검출기 생성하기 --- (*1)\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# 이미지를 읽어 들이고 그레이스케일로 변환하기 --- (*2)\n",
    "img = cv2.imread(\"face.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 얼굴 검출하기 --- (*3)\n",
    "face_list = cascade.detectMultiScale(img_gray)\n",
    "if len(face_list) == 0: \n",
    "    print(\"얼굴인식 실패\")\n",
    "else:\n",
    "    # 인식한 부분에 모자이크 처리하기 --- (*4)\n",
    "    for (x,y,w,h) in face_list:\n",
    "        img = mosaic(img, (x, y, x+w, y+h), 10)\n",
    "\n",
    "    # 이미지 출력하기\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 파이썬에서 노트북 카메라 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#현재 디바이스의 카메라를 호출하는 함수\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    #카메라에서 반복적으로 현재 프레임 확보\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "    #     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 카메라와 얼굴인식 결합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognize(frame):\n",
    "    # 캐스케이드 파일 지정해서 검출기 생성하기 --- (*1)\n",
    "    cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "    cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "    # 이미지를 읽어 들이고 그레이스케일로 변환하기 --- (*2)\n",
    "    img = frame\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 얼굴 인식하기 --- (*3)\n",
    "    face_list = cascade.detectMultiScale(img_gray)\n",
    "    # 결과 확인하기 --- (*4)\n",
    "    if len(face_list) == 0:\n",
    "#         print(\"얼굴 인식 실패\")\n",
    "        return\n",
    "    # 인식한 부분 표시하기 --- (*5)\n",
    "    for (x,y,w,h) in face_list:\n",
    "#         print(\"얼굴의 좌표 =\", x, y, w, h)\n",
    "        red = (0, 0, 255)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), red, thickness=20)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = face_recognize(frame)\n",
    "        try:\n",
    "            cv2.imshow('frame',frame)\n",
    "        except:\n",
    "            pass\n",
    "        keyboard = cv2.waitKey(1)\n",
    "\n",
    "        if keyboard & 0xFF == ord('q'):            \n",
    "            break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 카메라와 모자이크 결합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_mosaic(frame):\n",
    "    # 캐스케이드 파일 지정해서 검출기 생성하기 --- (*1)\n",
    "    cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "    cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "    # 이미지를 읽어 들이고 그레이스케일로 변환하기 --- (*2)\n",
    "    img = frame\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 얼굴 검출하기 --- (*3)\n",
    "    face_list = cascade.detectMultiScale(img_gray)\n",
    "    if len(face_list) == 0: \n",
    "        return\n",
    "\n",
    "    # 인식한 부분에 모자이크 처리하기 --- (*4)\n",
    "    for (x,y,w,h) in face_list:\n",
    "        img = mosaic(img, (x, y, x+w, y+h), 10)\n",
    "\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "\n",
    "        frame = face_mosaic(frame)\n",
    "        try:\n",
    "            cv2.imshow('frame',frame)\n",
    "        except:\n",
    "            pass\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://github.com/rintiantta/book-mlearn-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m streamlit run app.py\n",
    "#또는\n",
    "# !streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
